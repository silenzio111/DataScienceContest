# 面向不平衡二分类的堆叠融合与两阶段调参与校准：技术报告

作者：待填（队伍/单位）
版本：v1.0
仓库：`d:\Competition\数科统模`

## 摘要
在本项目中，我们围绕不平衡二分类问题构建了一套可复现的端到端方案，核心包括：系统化的特征工程（行统计与受约束的交互特征）、针对不同模型的差异化不平衡处理（线性模型折内 SMOTE，树模型类权重/scale_pos_weight）、两阶段超参数搜索（粗搜 + 邻域精调，并配合树模型后置早停微调迭代数），以及基于 Bagging 与嵌套校准（CalibratedClassifierCV）的 OOF Stacking 融合，最终以 AUPRC（平均精确率）作为主评估指标。实践表明，该流程在稳健性与泛化上效果良好，且具备明确的调参与优化路径。

关键词：不平衡学习、AUPRC、SMOTE、Stacking、模型校准、CatBoost、LightGBM、XGBoost、Logistic 回归

---

## 1. 引言
实际业务中，正负样本极度不均衡会导致模型在 ROC-AUC 高的情况下仍难以在召回-精确率层面满足需求。因此，我们选择对 PR 曲线下的面积（AUPRC）进行直接优化与评估，并围绕“稳健 + 可调 + 可复现”的原则设计了特征工程、建模与融合流水线。本报告系统梳理代码实现的逻辑，并总结了可落地的调参与优化策略。

## 2. 数据与问题设定
- 任务：二分类，不平衡。主指标：AUPRC（`sklearn.metrics.average_precision_score`）。
- 数据路径：
  - 训练集：`data/data(processed)/train.csv`
  - 测试集：`data/data(processed)/test.csv`
- 目标列：`target`（若数据中字段名不同，需在代码中调整 `TARGET` 变量）。
- ID 列：优先使用 `id` 或 `ID`；若不存在，提交文件按题面从 501 连续编号兜底。

## 3. 特征工程
实现位置：`code/logit_basde(smote_stacking) copy 3.ipynb`

3.1 列筛与类型识别
- 删除潜在的 ID 列（`id`/`ID`/`index`）。
- 自动识别数值列与类别列（当前流程主要面向数值列做统计与交互）。

3.2 行级统计特征（数值列）
- 统计量：sum、mean、std、min、max、非零计数（`row_nnz`）。
- 缺失值通过下游 `SimpleImputer(strategy='median')` 统一处理。

3.3 受约束的交互特征
- 初始交互：在最多 50 个数值特征中，生成不超过 25 对的乘积与比率特征（比率加入 `eps=1e-6` 防止除零）。
- 交互筛选：以与目标的 Spearman 相关（绝对值）为阈，低于 0.5 的交互会被丢弃。
- 扩展交互：
  - 基于当前数值特征的 Spearman 相关矩阵，寻找 |ρ|>0.8 的高相关特征对；
  - 避免重复/自交互，最多新增 20 对（仍生成乘积与比率）。
- 训练/测试特征对齐：确保测试集包含训练集的所有列，缺失列补 0，并按训练顺序对齐。

备注：以上阈值（交互对数量、相关性阈值等）均为可调超参，兼顾表达力与过拟合风险。

## 4. 不平衡处理策略
不同模型采用差异化策略，避免对树模型进行全局重采样而破坏其分布假设：
- 线性模型（两路 Logistic 与 Meta Logistic）：在交叉验证折内使用 SMOTE（`sampling_strategy=0.25`），仅对训练子集重采样；并配合标准化（`StandardScaler`）。
- 树模型：
  - XGBoost：设置 `scale_pos_weight = n_neg / n_pos`；
  - LightGBM：优先使用 `class_weight='balanced'`（或回退到 `scale_pos_weight`）；
  - CatBoost：使用 `class_weights=[1.0, scale_pos_weight]` 的数值列表形式。

## 5. 基学习器与融合框架
5.1 基学习器
- 线性：两路 `LogisticRegression`（不同随机种子与 C 初始值）。
- 树模型：`CatBoostClassifier`、`LGBMClassifier`、`XGBClassifier`（含合理初值与评估指标设置）。

5.2 OOF Stacking with Calibration + Bagging（核心）
- 自定义 `OOFStackingClassifier`：
  - 对每个基学习器先做 Bagging（默认 `n_bag=5`）；
  - 使用 `CalibratedClassifierCV(method='sigmoid', cv=3)` 做嵌套校准；
  - 以外层 5 折（StratifiedKFold）进行 `cross_val_predict`，得到校准后的 OOF 概率；
  - 将每个基学习器的 OOF 概率拼成 Meta 特征矩阵，训练 Meta 学习器（Logistic）。
- 预测阶段：对测试集分别获得各基学习器校准后的概率，拼成 Meta 特征后再由 Meta 输出最终概率。
- 顶层仅做缺失值填充（`SimpleImputer`），不在顶层做 SMOTE；数据平衡工作在各基学习器管道内完成。

## 6. 两阶段超参数搜索与后置早停微调
6.1 阶段一：随机粗搜索（RandomizedSearchCV）
- 不同模型有不同的搜索空间（示例）：
  - Logistic：`C ~ loguniform(1e-3, 3.0)`；
  - LightGBM：`n_estimators∈[150,600]`、`learning_rate ~ loguniform(0.01,0.3)`、`num_leaves∈[16,64]`、`max_depth∈[3,12]`、`subsample/colsample_bytree∈[0.6,1.0]`、`reg_lambda/reg_alpha ~ loguniform`；
  - CatBoost：`depth∈[4,10]`、`learning_rate ~ loguniform(0.01,0.3)`、`iterations∈[200,700]`、`l2_leaf_reg ~ loguniform(1,10)`；
  - XGBoost：`n_estimators∈[200,700]`、`max_depth∈[3,10]`、`learning_rate ~ loguniform(0.01,0.3)`、`subsample/colsample_bytree∈[0.6,1.0]`、`min_child_weight∈[1,7]`、`gamma ~ loguniform(1e-3,5)`、`reg_lambda/reg_alpha ~ loguniform`。
- 评估：`scoring='average_precision'`，3 折 StratifiedKFold；流水线内保持与正式训练一致的预处理（线性含 SMOTE）。

6.2 阶段二：邻域精调（GridSearchCV）
- 以阶段一的前 `top_k` 组超参为中心，围绕每个维度生成小范围“邻域”候选（浮点按比例缩放，整数 ±1 附近）；
- 将合并后的有限候选集以 GridSearch 方式精调，选择 AUPRC 最优配置；
- 重复参数去重，避免无效搜索；
- 最终返回最优模型（含预处理管道）。

6.3 树模型的后置早停微调（可选，默认开启）
- 目的：在一个快速的小验证切分上用原生 API 进行 early stopping，从而更精准地设定 `n_estimators/iterations`：
  - LightGBM：`lgb.train(..., early_stopping_rounds=50)`，度量可设为 `average_precision`；
  - XGBoost：`xgb.train(..., early_stopping_rounds=50, eval_metric='aucpr')`；
  - CatBoost：`use_best_model=True, od_wait=50`，训练后以 `best_iteration_` 回灌。
- 返回一个“未拟合的新实例”，仅更新迭代数，防止信息泄露，后续由 Stacking 在全数据上统一拟合。

补充：代码中提供了可选的“简化版 focal loss”用于早停阶段实验，但默认关闭以保证稳定性。

## 7. 评估协议与指标
- 交叉验证：5 折 StratifiedKFold（`shuffle=True, random_state=42`）。
- 主指标：AUPRC（平均精确率）。
  - 形式化地，给定按置信度排序的样本序列，AP 可写为：
  $$\mathrm{AP} = \sum_{k=1}^{n} P(k)\,\Delta R(k)$$
  其中 $P(k)$ 为前 $k$ 个样本的精确率，$\Delta R(k)$ 为召回的增量。

## 8. 提交流程
- 在全部训练数据上拟合顶层流水线（Imputer + OOF Stacking），对测试集输出概率；
- 构建提交文件：
  - 若测试集中存在 `id`/`ID` 列，使用其原值；
  - 否则按 `[501, 501+len(test))` 连续编号兜底；
- 保存到 `submit` 目录（代码中提供的示例文件名如 `（adjust3）stacking_logit_meta_logitC05_submission.csv`）。

## 9. 优化与调参建议（逐步可落地）
- 不平衡策略：
  - 优先确认正负样本比例，适度调小/调大 SMOTE 的 `sampling_strategy`（如 0.2~0.4）；
  - 树模型建议首选类权重/scale_pos_weight，必要时再做少量欠采样对比验证。
- 特征工程：
  - 放宽/收紧交互筛选阈值（如 Spearman 0.4~0.6），观察 AUPRC 与过拟合；
  - 逐步增加 `max_interactions` 与 `max_additional`，并配合正则较强的模型验证。
- 两阶段搜索：
  - 阶段一 `n_iter` 可在 10~50 内折中设定；
  - 阶段二邻域大小可按“当前最优值 × {0.85, 1.15}”一类比例进行微调；
  - 对时间敏感时优先调 Meta Logistic 的 `C`、XGB 的 `max_depth`/`min_child_weight`、LGB 的 `num_leaves`/`max_depth`。
- 融合细节：
  - Bagging 的 `n_bag` 从 3~7 试验；
  - 校准方法可对比 `sigmoid` 与 `isotonic`（样本足够时）；
  - Meta 学习器可尝试带类权重的 Logistic 或轻量树模型。
- 阈值选择：
  - 若最终需要二值化输出，可在验证集上扫描阈值以最大化 F1/Recall@Precision 等业务指标。

## 10. 消融研究（建议实施）
为量化各组件的贡献，建议依次只改变一个因素：
1) 仅基模型 + 简单平均；
2) + OOF（无校准）；
3) + 校准；
4) + Bagging；
5) + 两阶段调参；
6) + 后置早停微调；
7) + 扩展交互特征；
记录每一步的 5 折 AUPRC 均值与方差，绘制条形图或表格进行比较。

## 11. 复现环境与依赖
- 语言与库：Python 3.8+，Numpy，Pandas，scikit-learn，imbalanced-learn，LightGBM，XGBoost，CatBoost，SciPy。
- 重要随机种子：`random_state = 20050520`（个别组件内部另有种子）。
- 计算资源：CPU 即可（树模型可多线程），显存非必需。
- Windows 注意事项：路径使用原始 `ROOT = d:\\Competition\\数科统模`，避免转义错误。

## 12. 结论
本文给出了一套针对不平衡二分类的实战流水线：以 AUPRC 为核心优化目标，结合差异化的不平衡处理、两阶段调参与后置早停微调、以及基于 Bagging 的 OOF 校准型 Stacking。该流程在稳健性、可解释性与可调性间取得平衡，并提供了清晰的优化路线。后续可进一步探索：自适应交互特征搜索、基于验证集的动态阈值策略、以及与 Tabular 深度模型的互补融合。

## 参考文献（部分）
1. He, H. and Garcia, E. A. (2009). Learning from Imbalanced Data. IEEE TKDE.
2. Chawla, N. V. et al. (2002). SMOTE: Synthetic Minority Over-sampling Technique. J. Artificial Intelligence Research.
3. Wolpert, D. H. (1992). Stacked Generalization. Neural Networks.
4. Niculescu-Mizil, A. and Caruana, R. (2005). Predicting Good Probabilities with Supervised Learning. ICML.
5. LightGBM, XGBoost, CatBoost 官方文档与 scikit-learn/imbalanced-learn 文档。
