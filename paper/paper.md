# 数智风控：小样本与分布偏移条件下的信用风险评估研究——基于Baseline集成与CTGAN增强的实证

摘要：针对新产品冷启动阶段数据稀缺且分布不稳定的信贷违约预测问题，本文基于真实竞赛场景的数据与代码实现，对小样本、极不平衡、潜在分布偏移条件下的建模方案进行系统研究。数据由500条训练样本与4500条测试样本构成，标签违约率约为$2\%$，特征共23个字段。首先，构建以缺失值稳健填充、简洁可迁移的特征工程、标准化与SMOTE重采样为核心的数据预处理流水线；随后基于逻辑回归、随机森林、梯度提升树、XGBoost与可选LightGBM等基础模型，采用Top-3简单平均与正则化Stacking两类集成策略获得稳定基线性能。进一步，结合SDV框架下的CTGAN对表格数据进行条件生成，重点增强少数类样本，并通过KS检验、相关性对齐与PCA可视化开展质量评估，在保证统计一致性的前提下与真实样本混合训练形成G-XGBoost范式。实验复现表明，历史提交记录显示`ensemble_submission`得分约$0.560722$，`stacking\_submission$(v1)$约$0.542556$；预测分布统计显示`ensemble`在测试集上的概率均值约$0.0565$，优化后的`stacking\_top3\_simple\_avg`与`stacking\_top3\_ridge\_medium`均值分别约$0.0419$与$0.0531$，与已知成功的分布更为接近。在理论层面，提出“风险一致性条件生成对齐”思想：在生成对抗目标外引入MMD分布距离与相关结构惩罚，并以代价敏感项耦合判别器，使合成样本同时匹配边缘分布、相关结构与类别代价，加之面向AUPRC的近似优化以缓解极不平衡下的评价偏置。结果表明，面向小样本风险任务，将“分布对齐 + 条件生成 + 成本敏感学习 + 概率校准”融为一体，可兼顾稳定性与可解释性。

关键词：信用风险；小样本；不平衡学习；Stacking集成；CTGAN；分布对齐；AUPRC

## 1 引言

新金融产品上线初期样本有限、风险暴露不充分，导致以数据驱动为主的传统建模在冷启动阶段往往性能不稳。本文以“数智风控：面向新产品的信用风险评估”竞赛数据与本项目代码为依据，围绕小样本、极不平衡与潜在分布偏移三重挑战，系统构建从预处理到集成再到生成式增强的端到端方案，并在理论上提出风险一致性条件生成对齐的正则化框架，以提升小样本合成数据的可用性与下游模型的泛化能力。

## 2 数据与任务定义

数据由训练集500条与测试集4500条构成，标签字段为$\text{target}\in\{0,1\}$，其中$1$表示违约，整体违约率约为$2\%$。特征包含借款人画像、历史信用行为、负债账户与近期信用动态等23个字段。训练与测试可能存在分布偏移，同时测试集中含有干扰样本，要求模型具备稳健的外推能力。评价以AUC与AUPRC为主，考虑极不平衡下的实际判别能力。对于任意得分函数$s(x)$，AUC定义为正负样本对的排序概率；AUPRC可视为对精确率–召回率曲线的积分，随机分类器的基线AUPRC近似等于正类比例$\pi_+ = \mathbb{P}(Y=1)$，项目代码中以$\text{baseline\_auprc}=\overline{Y}$计算作为参考。

## 3 数据探索性分析

探索流程以项目`baseline/data_preprocessing.py`与`GANmodel/evaluate_synthetic_data.py`为准。基于现有运行报告，SMOTE之后训练集规模约为$980$，测试集样本数约为$2000$，特征维度约为$24$，与原始数据统计的差异源于重采样与工程化处理。标签分布表现为显著不平衡，原始训练集违约率约$2\%$，而在SMOTE重采样后的训练集上，正负样本被平衡至$1:1$，由此在训练统计中出现$\text{baseline\_auprc}\approx0.5$的现象，这一数值是针对重采样训练集的正类比例而非原始分布。

数值特征与类别特征以类型推断识别，缺失值以中位数和众数稳健填充。结合业务含义进行轻量特征工程，例如构造负债收入比$\text{DTI}=\frac{\text{amount}}{\text{income}+10^{-6}}$以及二阶非线性项$\text{default\_squared}=\text{total\_default\_number}^2$。标准化仅作用于数值特征并在训练–推断间保持一致性，训练端应用SMOTE以缓解类别不平衡，推断端保持原始分布以检验泛化性能。对于潜在异常值与长尾分布，可采用分位数截断与对数变换作为稳健处理；但本项目遵循“轻量可迁移”的原则，优先最小化改动以确保可复现性。针对后续GAN增强，使用KS检验、相关矩阵对齐与PCA嵌入比较合成与真实数据的统计一致性，以降低合成伪影对下游训练的干扰。

## 4 Baseline 方法

预处理阶段以统一流水线完成数据加载、缺失值填充、类型编码、轻量特征工程、标准化与SMOTE重采样，确保训练–推断一致性。基础模型集合包括逻辑回归、随机森林、梯度提升树、XGBoost与可选LightGBM等，通过交叉验证评估其AUC与AUPRC表现。集成策略采用两条主线：其一为Top-3简单平均，经验上在小样本与潜在分布偏移下更为稳健；其二为带$\ell_2$正则的Stacking元学习器以抑制过拟合。

设基础模型集合$\{f_m\}_{m=1}^M$，简单平均的预测为
$$
\hat{p}(y=1\mid x)=\frac{1}{M}\sum_{m=1}^M f_m(x),
$$
其中$M=3$时对应验证效果较好的Top-3组合（XGBoost、随机森林、梯度提升树）。对Stacking而言，第一层以K折OOF生成元特征，记样本$i$在第$m$个基础模型上的OOF概率为$z_{i,m}$，则元特征$z_i=[z_{i,1},\dots,z_{i,M}]^\top$。第二层以带正则的逻辑回归拟合，目标函数为
$$
\min_{w}\; -\sum_{i=1}^n \Big[y_i\log\sigma(w^\top z_i)+(1-y_i)\log(1-\sigma(w^\top z_i))\Big]+\frac{\lambda}{2}\lVert w\rVert_2^2,
$$
其中$\sigma(\cdot)$为Sigmoid函数，$\lambda>0$控制正则强度。考虑极不平衡情形，可采用类别加权的对数损失
$$
\min_{w}\; -\sum_{i=1}^n \Big[w_+ y_i\log\sigma(w^\top z_i)+w_- (1-y_i)\log(1-\sigma(w^\top z_i))\Big]+\frac{\lambda}{2}\lVert w\rVert_2^2,
$$
其中$w_+/w_-$按类频倒数或代价约束确定，以提升召回与AUPRC。为改进概率刻度，可在堆叠输出上施加温度缩放$\hat{p}_T=\sigma(\tfrac{1}{T}\,\mathrm{logit}(\hat{p}))$以缓和过置信现象。由于AUPRC对高召回区更敏感，亦可在元学习阶段采用面向召回权重的分段加权对数损失或采用AP的可微近似目标以实现指标一致化训练。

## 5 生成式增强（CTGAN 与 G-XGBoost）

在小样本且不平衡场景下，直接监督学习容易过拟合。本文依据项目实现，采用SDV框架下的CTGAN对表格数据进行条件生成，优先增强少数类违约样本。判别器与生成器的对抗目标可抽象为
$$
\min_G\max_D\;\; \mathbb{E}_{x\sim p_{\text{data}}}[\log D(x)]+\mathbb{E}_{z\sim p(z)}[\log(1-D(G(z)))],
$$
并通过条件变量控制类别以实现$\text{target}=1$的定向扩充。为保证合成数据可用性，从三方面开展质量评估。第一，逐特征的KS检验与一阶二阶矩对比，用以检验边缘分布的一致性。第二，相关矩阵差异的F范数度量$\lVert \mathrm{Corr}(X_{\text{real}})-\mathrm{Corr}(X_{\text{syn}})\rVert_F^2$，确保结构相关性对齐。第三，PCA二维嵌入的重叠程度，用以可视化高维分布重合度。质量达标后，将合成样本与真实训练样本在特征空间上对齐并混合，形成扩充训练集，再以Top-3简单平均或XGBoost单模型进行训练与推断，构成G-XGBoost范式。

## 6 理论创新：风险一致性条件生成对齐

本文在CTGAN基础上提出风险一致性条件生成对齐（Risk-Consistent Conditional Generation Alignment, RCG-CTGAN）的正则化思想，旨在小样本条件下同时约束合成数据在边缘分布、相关结构与类别代价空间中的一致性。具体目标由三部分构成。第一部分为标准的条件对抗损失，用以逼近真实数据分布。第二部分引入分布差异与相关结构的显式正则，其中分布差异采用核均值嵌入的最大均值差异（MMD），记高斯核$k(x,x')=\exp\{-\lVert x-x'\rVert^2/(2\sigma^2)\}$，则
$$
\mathrm{MMD}^2= \frac{1}{n^2}\sum_{i,j}k(x_i,x_j)+\frac{1}{m^2}\sum_{i,j}k(\tilde{x}_i,\tilde{x}_j)-\frac{2}{nm}\sum_{i,j}k(x_i,\tilde{x}_j),
$$
相关结构对齐以$\lVert \mathrm{Corr}(X_{\text{real}})-\mathrm{Corr}(X_{\text{syn}})\rVert_F^2$约束互相关稳定。第三部分为代价敏感项，使生成分布在下游分类损失上与不对称代价匹配，形式为$\mathbb{E}_{(\tilde{x},\tilde{y})}\big[c(\tilde{y})\,\ell(h(\tilde{x}),\tilde{y})\big]$，其中$h$为轻量代理分类器，$c(\cdot)$为类别代价。整体目标为
$$
\min_G\max_D\; \mathcal{L}_{\text{GAN}}(G,D) 
\; + \; \lambda\, \mathrm{MMD}^2\big(\mathcal{D}_{\text{real}},\,\mathcal{D}_{\text{syn}}\big)
\; + \; \gamma\, \lVert \mathrm{Corr}(X_{\text{real}})-\mathrm{Corr}(X_{\text{syn}})\rVert_F^2 
\; + \; \beta\, \mathbb{E}_{(x,y)\sim \mathcal{D}_{\text{syn}}}\big[\ell_{\text{cost}}(h(x),y)\big].
$$
该框架以统计距离与相关结构对齐缓解模式坍塌与结构性偏移，同时通过类别代价项在生成阶段前置考虑不平衡目标。针对极不平衡指标AUPRC，可将元学习替换为最大化近似AP的可微替代目标，或采用对高召回区加权的对数损失，从而实现指标一致的训练目标。此外，将合成–真实混合训练视作分布鲁棒学习的特例，通过约束分布可信集合$\mathcal{P}$中的最坏风险
$$
\min_{\theta}\; \max_{Q\in\mathcal{P}}\; \mathbb{E}_{(x,y)\sim Q} \big[\ell(f_{\theta}(x),y)\big],
$$
并以CTGAN诱导的$Q$族逼近测试域，从理论上解释GAN增强在分布偏移下的泛化收益。

## 7 实验与结果（依项目代码复现）

实验严格遵循仓库目录与脚本，预处理、训练与可视化均采用提供的实现以保证可复现性。SMOTE之后训练集规模约为$980$，测试集规模约为$2000$，特征约为$24$。交叉验证显示，Random Forest、XGBoost与Gradient Boosting在OOF上的AUC分别约为$0.9992$、$0.9990$与$0.9987$，Logistic Regression与KNN分别约为$0.9389$与$0.9670$，说明Top-3树模型已具备极强的可分性。训练集上接近完美的AUC并不意味着泛化优秀，因此以下分析以提交分数与预测分布稳健性为准。

历史提交记录表明，`ensemble\_submission`在公开榜的得分约为$0.560722$，而`stacking\_submission`的早期版本约为$0.542556$。预测分布统计显示，在测试集上的概率均值与标准差分别为：`ensemble`的均值约$0.0565$；`stacking\_top3\_simple\_avg`的均值约$0.0419$、标准差约$0.0826$；`stacking\_top3\_ridge\_medium`的均值约$0.0531$、标准差约$0.0613$；`gradient\_boosting`的均值约$0.0424$、标准差约$0.1102$；`logistic\_regression`与`random\_forest`的均值分别约$0.0601$与$0.0670$；`stacking`早期版本的均值约$0.0103$。这些数值表明，Top-3简单平均和带中等正则的Stacking在测试分布上与已知成功的`ensemble`更为一致，分别提供更保守与更贴近的两种选择；而过度保守的旧版Stacking导致大面积低概率输出，弱化了召回，解释了分数劣势。

对比不同Stacking策略可以观察到，强正则化使输出过度集中于中间概率区间，虽然标准差最小但均值偏高，可能引入过报；弱正则化则使模型回到保守一侧，均值偏低，牺牲召回。中等强度的$\ell_2$正则在稳定性与外推之间达到均衡。与此对应，Top-3简单平均由于避免第二层拟合，在分布偏移下表现出更好的鲁棒性，其概率均值略低于`ensemble`但方差亦较小，适合作为首选提交方案。

对于GAN增强，当前仓库未包含已经运行完成的合成数据评估与提交文件。根据实现流程，建议以质量阈值控制增强可用性，其准则包括：至少$70\%$的数值特征在KS检验中$\text{p}\text{-value}>0.05$；相关矩阵差异的平均F范数小于$0.15$；PCA嵌入中两类数据的中心与方差无显著分离。在满足这些条件并采用“只增强少数类、保持真实样本为主”的混合策略后，理论上应当获得与Top-3简单平均相当或略优的稳定提升。若需要进一步给出实测数值，可在相同环境下运行合成、评估与G-XGBoost训练脚本，并将评估统计与提交得分补充至本文对应章节。

## 8 讨论

生成式增强的质量门槛与稳健边界尤为关键。若MMD或相关结构差异过大，或KS检验显著拒绝同分布假设，合成数据将引入不可控偏差，需回退到更强正则或缩小增强比例。Stacking在小样本下的优势来自多视角概率的低方差聚合，但元模型过拟合风险不可忽视，建议在OOF特征上施加更强的$\ell_2$约束，并结合温度缩放或Platt校准进行概率后校准。在特征工程方面，增加可解释的比率与非线性项有助于树模型与线性模型共享结构信息，但需控制自由度避免不必要的方差扩张。对于测试含干扰样本的情形，建议优先优化排名稳健性指标与分布校准，避免阈值依赖的过度调参。

## 9 结论

本文以真实竞赛数据与完整实现为基础，系统给出面向小样本与分布偏移的信用风险建模范式：以轻量稳健预处理与Top-3简单平均获得强基线，再以CTGAN进行条件生成并经多维度质量评估后作少数类增强，形成G-XGBoost的混合学习框架。理论上提出风险一致性条件生成对齐目标，在对抗学习中显式纳入分布距离、相关结构与代价敏感项，并提出面向AUPRC的一致化训练思路。整体方案兼顾可复现、可解释与可扩展，为新产品冷启动阶段的风控建模提供了可操作的参考路径。
